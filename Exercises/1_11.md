# Exercise
The maximum likelihood function can be expressed as

Prove that the maximum likelihood for the normal distribution if we maximize with respect to $\mu$ gives as its solution the sample mean:
$$
\mu_{\operatorname{ML}} = \frac{1}{N} \sum_{n = 1}^N x_n.
$$

If we maximize with respect to $\sigma^2$ we get the sample variance
$$
\sigma^2_{\operatorname{ML}} = \frac{1}{N}\sum_{n = 1}^N(x - \mu_{\operatorname{ML}})^2.
$$
# Solution
Following the book we can express the log likelihood by
$$
\log p(x|\mu,\sigma^2) = - \frac{1}{2\sigma^2} \sum_{n = 1}^N (x_n - \mu)^2 - \frac{N}{2} \log(\sigma^2) - \frac{N}{2} ln(2\pi).
$$
If we look at this as a function $f(\mu)$ only of $\mu$ we get
$$
\begin{aligned}
f'(\mu) &= -\frac{1}{2\sigma^2} \sum_{n = 1}^N \frac{d}{d\mu} (x_n - \mu)^2 \\
&= -\frac{1}{2\sigma^2}\sum_{n = 1}^N (-2)(x_n - \mu) \\
&= \sigma^{-2}\sum_{n = 1}^N (x_n - \mu)
\end{aligned}
$$
This is equal to $0$ if and only if
$$
\sum_{n = 1}^N x_n = \sum_{n = 1}^N \mu = N\mu,
$$
i.e., when
$$
\mu = \frac{1}{N}\sum_{n = 1}^N x_n,
$$
i.e., when $\mu$ is the sample mean of $(x_1, \dots, x_N)$.

Now we want to derive the sample variance, we interpret the log likelihood
$$
\log p(x|\mu,\sigma^2) = - \frac{1}{2\sigma^2} \sum_{n = 1}^N (x_n - \mu)^2 - \frac{N}{2} \log(\sigma^2) - \frac{N}{2} ln(2\pi).
$$
as a function $g(\sigma^2)$ and note that
$$
g'(\sigma^2) = \frac{1}{2(\sigma^2)^2} \sum_{n = 1}^N (x_n - \mu)^2 - \frac{N}{2\sigma^2}.
$$
This is equal to $0$ if and only if
$$
\frac{N}{2\sigma^2} = \frac{1}{2(\sigma^2)^2} \sum_{n = 1}^N (x_n - \mu)^2,
$$
multiplying both sides by $2(\sigma^2)^2$ yields
$$
\sigma^2N = \sum_{n = 1}^N (x_n - \mu)^2,
$$
inserting our sample mean then gives us the sample variance
$$
\sigma^2 = \frac{1}{N}\sum_{n = 1}^N (x_n - \mu_{\operatorname{ML}})^2
$$